<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns:madcap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" madcap:lastblockdepth="2" madcap:lastheight="135.6667" madcap:lastwidth="592" madcap:disablemasterstylesheet="true" madcap:tocpath="Feature Extraction" madcap:medium="non-print" madcap:inpreviewmode="false" madcap:preloadimages="false" madcap:runtimefiletype="Topic" madcap:targettype="WebHelp" lang="en-us" xml:lang="en-us" madcap:pathtohelpsystem="../../../" madcap:helpsystemfilename="ENVIHelp.xml" madcap:searchtype="Stem">
 <!-- saved from url=(0014)about:internet -->
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>
   Example-Based Classification
  </title>
  <link href="../../SkinSupport/MadCap.css" rel="stylesheet" />
  <link href="../../Resources/Stylesheets/Doc_Style.css" rel="stylesheet" />
  <script src="../../SkinSupport/MadCapAll.js" type="text/javascript">
  </script>
 </head>
 <body>
  <p class="MCWebHelpFramesetLink" style="display: none;">
   <a href="../../../ENVIHelp_CSH.htm#FindFeatures/FeatureExtraction/Example_Based_Classification.htm" style="">
    Open topic with navigation
   </a>
  </p>
  <div class="MCBreadcrumbsBox_0">
   <span class="MCBreadcrumbsPrefix">
    <![CDATA[ ]]>
   </span>
   <a class="MCBreadcrumbsLink" href="ExtractFeatures.htm">
    Feature Extraction
   </a>
   <span class="MCBreadcrumbsDivider">
    &gt;
   </span>
   <span class="MCBreadcrumbs">
    Example-Based
   </span>
  </div>
  <h1>
   Example-Based Classification
   <a name="kanchor314">
   </a>
  </h1>
  <p>
   <img src="../../Resources/Images/IconsButtons/Tutorial.gif" class="VertCenter" />
   <![CDATA[ ]]>
   <a href="../../Tutorials/Workflows/FXExampleBasedTutorial.htm">
    Feature Extraction with Example Based Classification Tutorial
   </a>
  </p>
  <p>
   Example-based, or supervised, classification is the process of using training data
   <![CDATA[ ]]>
   to assign objects of unknown identity to one or more known features. The more features and training samples you select, the better the results from supervised classification.
  </p>
  <p>
   See the following sections:
  </p>
  <ul>
   <li value="1">
    <a href="#SelectInputFiles">
     Select Input Files for Feature Extraction
    </a>
   </li>
   <li value="2">
    <a href="#SegmentImages">
     Segment Images
    </a>
   </li>
   <li value="3">
    <a href="#Selectin2">
     Select Training Data
    </a>
   </li>
   <li value="4">
    <a href="#Saving">
     Save Training Data
    </a>
   </li>
   <li value="5">
    <a href="#Ground">
     Import Ground Truth Data
    </a>
   </li>
   <li value="6">
    <a href="#Selectin">
     Select Attributes for Classification
    </a>
   </li>
   <li value="7">
    <a href="#Selectin3">
     Select a Classification Method (Advanced)
    </a>
   </li>
   <li value="8">
    <a href="#Export">
     Export Classification Results
    </a>
   </li>
  </ul>
  <p>
   From the Toolbox, select
   <b>
    Feature Extraction &gt; Example Based &gt; Feature Extraction Workflow
   </b>
   . The Data Selection panel appears.
  </p>
  <h2>
   <a name="SelectInputFiles">
   </a>
   Select Input Files for Feature Extraction
  </h2>
  <p>
   For best results with Feature Extraction, consider preprocessing your imagery to reduce noisy or redundant data, to correct for atmospheric effects, or to suppress vegetation. See
   <a href="../../PreprocessImagery/PreprocessImagery.htm">
    Preprocess Imagery
   </a>
   for available options.
  </p>
  <p>
   For hyperspectral imagery, we strongly recommend that you run a
   <a href="../../PreprocessImagery/Transforms/PrincipalComponentAnalysis.htm">
    principal components analysis
   </a>
   or
   <a href="../../PreprocessImagery/Transforms/IndependentComponentsAnalysis.htm">
    independent components analysis
   </a>
   on the dataset before using it in Feature Extraction. Segmentation and merging work best on datasets with only a few bands.
  </p>
  <p>
   Also consider reducing the spatial resolution of your input image to speed up processing and to remove small, unwanted features. For example, you can down-sample a 10,000 by 10,000 pixel image by a factor of 10 to yield a 1,000 by 1,000 pixel image.
  </p>
  <ol>
   <li value="1">
    Click
    <b>
     Browse
    </b>
    and select a panchromatic or multispectral image for input. Feature Extraction accepts any image format listed in
    <a href="../../ExploreImagery/SupportedFormats.htm">
     Supported File Formats
    </a>
    .
   </li>
   <li value="2">
    You can perform optional spatial or spectral
    <a href="../../NoTOCTopics/Subsetting.htm">
     subsetting
    </a>
    from within the Select Input File dialog.
   </li>
   <li value="3">
    To apply a
    <a href="../../NoTOCTopics/WorkingWithMasks.htm">
     mask
    </a>
    , select the Input Mask tab in the File Selection panel. In addition to the mask, any pixel values specified in the
    <b>
     Data Ignore Value
    </b>
    field of the associated header (for
    <a href="../../ExploreImagery/ENVIImageFiles.htm">
     <span class="DocumentTitleProductName">
      ENVI
     </span>
     -format files
    </a>
    ) will be treated as mask values and will not be processed by Feature Extraction.
   </li>
   <li madcap:conditions="" value="4">
    You can import ancillary data to help extract features of interest. An example is combining a LiDAR digital surface model (DSM) with a multispectral image to identify rooftops in a residential area, then
    <a href="Rule_Based_Classification.htm">
     building a rule
    </a>
    using height data from the DSM to more accurately extract the rooftops. (The height data would be in the
    <code>
     Spectral Mean
    </code>
    <![CDATA[ ]]>
    <a href="AttributeList.htm">
     attribute
    </a>
    for the DSM band.) Multiple datasets often provide more accurate results. The following rules apply:
    <ul>
     <li madcap:conditions="" value="1">
      You can only use raster data for ancillary data. Vector data must be converted to raster format prior to import.
     </li>
     <li madcap:conditions="" value="2">
      The ancillary image file must be georeferenced to a standard map projection or use
      <a href="../../GeorectifyImagery/BackgroundNonStandardProjections.htm#Sensor">
       rational polynomial coefficients
      </a>
      (RPCs). If the ancillary data is not in the same map projection as the input image,
      <span class="DocumentTitleProductName">
       ENVI
      </span>
      will reproject the ancillary data to match the base projection. Images with arbitrary map projections or
      <a href="../../GeorectifyImagery/BackgroundNonStandardProjections.htm">
       affine map transformations
      </a>
      (designated as "pseudo" in the Data Manager) cannot be used as ancillary data.
     </li>
     <li madcap:conditions="" value="3">
      The ancillary data and input image must have some geographic overlap.
     </li>
     <li madcap:conditions="" value="4">
      If you spatially subset the input image, the ancillary data will be reprojected to match that spatial extent.
     </li>
    </ul>
   </li>
   <p madcap:conditions="">
    Select the Ancillary Data tab and click
    <b>
     Add Data
    </b>
    . Select one or more ancillary files for input. You can select spectral subsets from each ancillary data file.
    <span class="DocumentTitleProductName">
     ENVI
    </span>
    will create new bands for each ancillary file that you import; you can then use these bands for
    <a href="Rule_Based_Classification.htm">
     rule-based classification
    </a>
    . The ancillary bands are identified by the name of the ancillary file and the respective band number of that file.
   </p>
   <li value="5">
    Select the Custom Bands tab and enable the following options if desired. The input image must be georeferenced to a standard map projection for these options to be available.
    <ul>
     <li madcap:conditions="" value="1">
      <b>
       Normalized Difference:
      </b>
      Select two bands for computing a normalized band ratio as follows:
     </li>
     <p class="indent" madcap:conditions="">
      [(b2 - b1) / (b2 + b1 + eps)]
     </p>
     <p class="indent" madcap:conditions="">
      Where "eps" is a very small number to avoid division by zero.
     </p>
     <p madcap:conditions="">
      If b2 is near-infrared and b1 is red, then
      <b>
       Normalized Difference
      </b>
      will be a measure of normalized difference vegetation index (NDVI).
     </p>
     <p madcap:conditions="">
      For example, if you have a QuickBird image with four bands where Band 3 is red and Band 4 is near-infrared and you want to compute NDVI, select
      <b>
       Band 3
      </b>
      from the
      <b>
       Band 1
      </b>
      drop-down list. Select
      <b>
       Band 4
      </b>
      from the
      <b>
       Band 2
      </b>
      drop-down list.
     </p>
     <p madcap:conditions="">
      <span class="DocumentTitleProductName">
       ENVI
      </span>
      will create a "Normalized Difference" band that you can use for segmentation or classification.
     </p>
     <li madcap:conditions="" value="2">
      <b>
       Color Space:
      </b>
      Select the
      <b>
       Red
      </b>
      ,
      <b>
       Green
      </b>
      , and
      <b>
       Blue
      </b>
      band names from the image.
      <span class="DocumentTitleProductName">
       ENVI
      </span>
      will perform an RGB to HSI color space transformation and will create new bands for Hue, Saturation, and Intensity that you can use for segmentation or
      <a href="BackgroundRuleClassification.htm">
       rule-based classification
      </a>
      .
     </li>
     <p class="indent" madcap:conditions="">
      <b>
       Hue:
      </b>
      Often used as a color filter, measured in degrees from 0 to 360. A value of 0 is red, 120 is green, and 240 is blue.
     </p>
     <p class="indent" madcap:conditions="">
      <b>
       Saturation:
      </b>
      Often used as a color filter, measured in floating-point values that range from 0 to 1.0.
     </p>
     <p class="indent" madcap:conditions="">
      <b>
       Intensity:
      </b>
      Often provides a better measure of brightness than the
      <code>
       Spectral_Mean
      </code>
      spectral attributes. Intensity is measured in floating-point values that range from 0 to 1.0.
     </p>
    </ul>
   </li>
   <p madcap:conditions="" class="Note" madcap:autonum="&lt;b&gt;Note: &lt;/b&gt;">
    <span class="autonumber">
     <span>
      <b>
       Note:
      </b>
     </span>
    </span>
    You should not perform segmentation with a combination of custom bands (normalized difference or HSI color space) and visible/NIR bands. You can perform segmentation on the normalized difference or color space bands by themselves, but not in combination with visible and NIR bands.
   </p>
   <li madcap:conditions="" value="6">
    Click
    <b>
     Next
    </b>
    .
   </li>
  </ol>
  <p madcap:conditions="">
   <span class="DocumentTitleProductName">
    ENVI
   </span>
   will create a single dataset  from the combined bands of the input image, ancillary data, normalized difference, hue, saturation, and intensity (if selected). This single dataset will be used throughout the rest of the Feature Extraction workflow.
  </p>
  <p madcap:conditions="">
   When file selection is complete, the file opens in a new workflow view. If the selected file is displayed in an active view before you start the workflow, the display bands and image location are retained, as well as  any brightness, contrast, stretch, and sharpen settings. The image location is not retained for pixel-based images or those with pseudo or arbitrary projections.
  </p>
  <h2>
   <a name="SegmentImages">
   </a>
   Segment Images
  </h2>
  <p>
   Segmentation is the process of partitioning an image into objects by grouping neighboring pixels with common values. The objects in the image ideally correspond to real-world features. Effective segmentation ensures that classification results are more accurate.
  </p>
  <ol>
   <li value="1">
    Enable the
    <b>
     Preview
    </b>
    option in the Object Creation panel. A Preview Portal appears with segments outlined in green.
   </li>
   <li value="2">
    Under
    <b>
     Segment Settings
    </b>
    , select an
    <b>
     Algorithm
    </b>
    from the drop-down list provided. The following options are available:
    <ul>
     <li value="1">
      <b>
       Edge:
      </b>
      Best for detecting edges of features where objects of interest have sharp edges. Set an appropriate
      <b>
       Scale Level
      </b>
      and
      <b>
       Merge Level
      </b>
      (see steps below) to effectively delineate features.
     </li>
     <li value="2">
      <b>
       Intensity:
      </b>
      Best for segmenting images with subtle gradients such as digital elevation models (DEMs) or images of electromagnetic fields. When selecting this method, don't perform any merging; set the
      <b>
       Merge Level
      </b>
      to
      <b>
       0
      </b>
      . Merging is used primarily to combine segments with similar spectral information. Elevation and other related attributes are not appropriate for merging.
     </li>
    </ul>
   </li>
   <p>
    See
    <a href="BackgroundSegmentationAlgorithm.htm">
     Watershed Algorithm Background
    </a>
    for more detailed descriptions of each option.
   </p>
   <li value="3">
    Adjust the
    <b>
     Scale Level
    </b>
    slider as needed to effectively delineate the boundaries of features as much as possible without
    <i>
     over
    </i>
    -segmenting the features. Increasing the slider results in fewer segments; decreasing the slider results in more segments. You should also ensure that features of interest are not grouped into segments represented by other features. See
    <a href="BackgroundSegmentationAlgorithm.htm">
     Watershed Algorithm Background
    </a>
    for a more detailed discussion of how the
    <b>
     Scale Level
    </b>
    is used with respect to gradient and intensity images.
   </li>
   <li value="4">
    Click the
    <b>
     Select Segment Bands
    </b>
    button to choose specific bands for applying the segmentation settings. The settings will apply to a grayscale image derived from the average of all selected bands. All available bands are selected by default.
   </li>
   <p class="Tip" madcap:autonum="&lt;b&gt;Tip: &lt;/b&gt;">
    <span class="autonumber">
     <span>
      <b>
       Tip:
      </b>
     </span>
    </span>
    For best segmentation results, select a combination of bands that have similar spectral ranges such as R, G, B, and NIR bands. You should not perform segmentation with a combination of custom bands (normalized difference or HSI color space) and visible/NIR bands. You can perform segmentation on the normalized difference or color space bands by themselves, but not in combination with visible and NIR bands.
   </p>
   <li value="5">
    Merging combines adjacent segments with similar spectral attributes. Under
    <b>
     Merge Settings
    </b>
    , select an
    <b>
     Algorithm
    </b>
    from the drop-down list provided. The following options are available:
    <ul>
     <li value="1">
      <b>
       Full Lambda Schedule:
      </b>
      (default). Merges small segments within larger, textured areas such as trees or clouds, where over-segmentation may be a problem.
     </li>
     <li value="2">
      <b>
       Fast Lambda:
      </b>
      Merges adjacent segments with similar colors and border sizes.
     </li>
    </ul>
   </li>
   <p>
    See
    <a href="BackgroundMergeAlgorithms.htm">
     Merge Algorithms Background
    </a>
    for more detailed descriptions of each option.
   </p>
   <li value="6">
    Adjust the
    <b>
     Merge Level
    </b>
    slider as needed to combine segments with similar colors (Fast Lambda) or to merge over-segmented areas (Full Lambda Schedule). Increasing the slider results in more merging; no merging will occur if you leave the slider value at 0. For example, if a red building consists of three segments, selecting
    <b>
     Fast Lambda
    </b>
    <![CDATA[ ]]>
    and increasing the
    <b>
     Merge Level
    </b>
    should combine them into one segment. All available bands are selected by default. To delineate treetops or other highly textured features, select
    <b>
     Full Lambda Schedule
    </b>
    and increase the
    <b>
     Merge Level
    </b>
    value.
   </li>
   <li value="7">
    Click the
    <b>
     Select Merge Bands
    </b>
    button to choose specific bands for applying the merge settings. Merging will be based on the differences between region colors based on all selected bands.
   </li>
   <li value="8">
    Select a
    <b>
     Texture Kernel Size
    </b>
    value, which is the size (in pixels) of a moving box centered over each pixel in the image.
    <a href="AttributeList.htm#texture_attributes">
     Texture attributes
    </a>
    are computed for each kernel. Enter an odd number of 3 or higher. The maximum value is 19. The default value is 3. Select a higher kernel size if you are segmenting large areas with little texture variance such as fields. Select a lower kernel size if you are segmenting smaller areas with higher variance such as urban neighborhoods.
   </li>
   <li value="9">
    Click
    <b>
     Next
    </b>
    .
    <span class="DocumentTitleProductName">
     ENVI
    </span>
    loads a segmentation image into the display.
   </li>
  </ol>
  <h2>
   <a name="Selectin2">
   </a>
   Select Training Data
   <a name="kanchor315">
   </a>
  </h2>
  <p>
   The Example-Based Classification panel contains a folder called All Classes that will contain all of the feature types (classes) that you define. A new, undefined class is available for you to start defining training data.
  </p>
  <ol>
   <li value="1">
    Select the new class, and edit its name and color within the Class Properties table.
   </li>
   <li value="2">
    As you move around the segmentation image, the regions underneath your cursor are highlighted in cyan. Click on a highlighted region to assign it to that class. The color of the region changes to the feature color, and the class name updates to show the number of training regions you added.
   </li>
   <p class="Tip" madcap:autonum="&lt;b&gt;Tip: &lt;/b&gt;">
    <span class="autonumber">
     <span>
      <b>
       Tip:
      </b>
     </span>
    </span>
    Suppose you created a new class called "Vegetation."&#160;Move your cursor around the image and highlight a region that you know represents vegetation. Click on the region to select it. To view the original image instead of the segmentation image, set the
    <b>
     Transparency
    </b>
    slider in the main toolbar to 100% transparency.
   </p>
   <p>
    The color variations of the segments in the segmentation image may be so small that you cannot discern them. Enable the
    <b>
     Show Boundaries
    </b>
    option to outline the segments so they are easier to visualize.
   </p>
   <p>
    Continue selecting training regions that best represent your class. Try to select regions with different textures, shades, and sizes.
   </p>
   <p>
    Another way to select training regions is to draw a box around a group of adjacent segments; however selecting a large number of segments could result in slower processing.
   </p>
   <ul>
    <li value="1">
     To remove an individual region from selection, click on it again.
    </li>
    <li value="2">
     To assign a training region to a
     <i>
      different
     </i>
     class, first select the class that you want to assign it to. Then select the training region. It changes color to reflect the newly assigned class.
    </li>
    <li value="3">
     To create a new class, select the class name and click the
     <b>
      Add Class
     </b>
     button.
    </li>
    <li value="4">
     To delete a class, select the class name and click the
     <b>
      Remove Class
     </b>
     button.
    </li>
   </ul>
  </ol>
  <h2>
   <a name="Saving">
   </a>
   Save Training Data
  </h2>
  <p>
   To save your training data for all classes to a point shapefile, click the
   <b>
    Save Example File
   </b>
   button.
   <span class="DocumentTitleProductName">
    ENVI
   </span>
   saves the pixel coordinates of the points where you clicked when selecting training regions, along with map coordinates if the image is georeferenced.
  </p>
  <p>
   A training data shapefile only contains the locations of training regions; it does not include other parameters you selected for example-based classification such as the classification method, selected attributes, etc.
  </p>
  <p>
   You can later restore the training data file by clicking the
   <b>
    Restore Example File
   </b>
   button. The restored data will overwrite any training data you have defined in the curent session. You cannot restore a pixel-based training data file for use with a georeferenced image. After restoring the file, you can click
   <b>
    Back
   </b>
   to readjust your segmentation settings if needed, but the training regions will  change based on the new segmentation result.
  </p>
  <h2>
   <a name="Ground">
   </a>
   Import Ground Truth Data
  </h2>
  <p>
   Ground truth data defines areas of an image with known feature types, thus it represents a true classification for specific areas of the image. You can import ground truth data from the following sources when performing supervised classification:
  </p>
  <ul>
   <li value="1">
    Point and polygon shapefiles.
   </li>
   <li value="2">
    3D point and polygon shapefiles.
   </li>
  </ul>
  <p class="Tip" madcap:autonum="&lt;b&gt;Tip: &lt;/b&gt;">
   <span class="autonumber">
    <span>
     <b>
      Tip:
     </b>
    </span>
   </span>
   An example of ground truth data is a land-cover classification shapefile or geological map of your area of interest, which may be available from websites of local government agencies.
  </p>
  <ol>
   <li value="1">
    Under the Examples Selection tab, click the
    <b>
     Import Ground Truth
    </b>
    button. This button is enabled for georeferenced input images only.
   </li>
   <li value="2">
    Importing a ground truth file will overwrite any existing training samples that you have collected. When prompted to disregard the currently loaded example file, click
    <b>
     Yes
    </b>
    . The Select Input File dialog appears.
   </li>
   <li value="3">
    Click
    <b>
     Open File
    </b>
    and select a 2D or 3D point or polygon shapefile with ground truth data. Click
    <b>
     OK
    </b>
    . The Select Attribute dialog appears.
   </li>
   <li value="4">
    From the
    <b>
     Select Attribute
    </b>
    drop-down list, select the shapefile attribute to group vector records into training classes. The default is CLASS_ID. You should choose unambiguous attribute fields for grouping records into training classes.
   </li>
   <p>
    You can specify class colors by adding a CLASS_CLRS attribute to the ground truth shapefile. Use this attribute field to specify class colors using a string of RGB values (for example, enter
    <code>
     '255,0,0'
    </code>
    for Red). If the shapefile contains CLASS_NAME and CLASS_CLRS attributes and you select the CLASS_ID attribute from the
    <b>
     Select Attribute
    </b>
    drop-down list, the proper class names and colors will be restored. If the shapefile does not contain CLASS_NAME and CLASS_CLRS attributes,
    <span class="DocumentTitleProductName">
     ENVI
    </span>
    will assign unique names and colors to each class. You can rename them in the Example-Based Classification panel if desired.
   </p>
   <li value="5">
    Regions in the segmentation image that overlap any vector records in the shapefile will become training samples for the corresponding class. Vector records that do not overlap the input image will be ignored. If you select
    <b>
     Use Centroid
    </b>
    , a region will become a training region only if the centroid of the polygon (instead of any part of the polygon) falls within the region. A
    <i>
     centroid
    </i>
    is the geometric center of a polygon.
   </li>
   <li value="6">
    Click
    <b>
     Import
    </b>
    . A new class will be created for each unique CLASS_ID or other attribute value that you choose.
   </li>
  </ol>
  <h2>
   <a name="Selectin">
   </a>
   Select Attributes for Classification
  </h2>
  <p>
   This section describes how to choose attributes that will be used to classify your training samples. Click the Attributes Selection tab to see the available options. By default,
   <i>
    all
   </i>
   <![CDATA[ ]]>
   attributes will be used for classification.
  </p>
  <p class="Note" madcap:autonum="&lt;b&gt;Note: &lt;/b&gt;">
   <span class="autonumber">
    <span>
     <b>
      Note:
     </b>
    </span>
   </span>
   This section is disabled for PCA classification since all attributes are used with that method.
  </p>
  <ul>
   <li value="1">
    The
    <b>
     Available Attributes
    </b>
    column shows the attributes that are available for you to choose from. See
    <a href="AttributeList.htm">
     List of Attributes
    </a>
    for their definitions. Expand the Spatial, Spectral, and Texture groups to see individual attributes.
   </li>
   <li value="2">
    The
    <b>
     Selected Attributes
    </b>
    column shows the attributes that will be used in classification. By default,
    <i>
     all
    </i>
    spatial, spectral, and texture attributes are initially included. You cannot proceed with example-based classification until you select at least one attribute for classification.
   </li>
   <li value="3">
    To remove one or more attributes from the
    <b>
     Selected Attributes
    </b>
    column, select the attribute name(s) and click the
    <b>
     &lt;
    </b>
    button.
   </li>
   <li value="4">
    To add an individual attribute back to the
    <b>
     Selected Attributes
    </b>
    column, select the attribute name(s) in the
    <b>
     Available Attributes
    </b>
    column and click the
    <b>
     &gt;
    </b>
    button.
   </li>
   <li value="5">
    To add groups of attributes to the
    <b>
     Selected Attributes
    </b>
    column, select
    <b>
     Spatial
    </b>
    ,
    <b>
     Spectral
    </b>
    , or
    <b>
     Texture
    </b>
    in the
    <b>
     Available Attributes
    </b>
    column, and click the
    <b>
     &gt;
    </b>
    button.
   </li>
  </ul>
  <ul>
   <li value="1">
    To perform classification with only a few attributes (instead of all of them), select the
    <b>
     Selected Attributes
    </b>
    folder in the right column and click the
    <b>
     &lt;
    </b>
    button. Then under the
    <b>
     Available Attributes
    </b>
    column, select the few attributes you want to use for classification and click the
    <b>
     &gt;
    </b>
    button.
   </li>
   <li value="2">
    Spectral and texture attributes are computed for each band of your image. When selecting spectral and texture attributes for classification, select the specific bands to include by using the check boxes provided. Or use the
    <b>
     Select All
    </b>
    or
    <b>
     Deselect all
    </b>
    button. You can also remove a specific band by selecting it under the
    <b>
     Selected Attributes
    </b>
    column and unchecking it in the band list.
   </li>
   <li value="3">
    Click
    <b>
     Auto Select Attributes
    </b>
    to have
    <span class="DocumentTitleProductName">
     ENVI
    </span>
    determine the best attributes to use for classifying features. The underlying logic is based on the reference below. This button is enabled once you define at least two classes with at least two training samples each. The more classes and training samples you have, the slower the process.
   </li>
  </ul>
  <p style="font-weight: normal;">
   <b>
    Reference
   </b>
  </p>
  <p>
   <i>
    An interval based attribute ranking technique
   </i>
   . Unpublished report,
   <span class="DocumentTitleCompanyName">
    Exelis
   </span>
   . A copy of this paper is available from
   <span class="DocumentTitleCompanyName">
    Exelis
   </span>
   Technical Support.
  </p>
  <h2>
   <a name="Selectin3">
   </a>
   Select a Classification Method (Advanced)
  </h2>
  <p>
   Three methods are available to perform supervised classification. Click the Algorithms tab and select a method from the
   <b>
    Algorithms
   </b>
   drop-down list. See one of the following sections:
  </p>
  <ul>
   <li value="1">
    <b>
     KNN:
    </b>
    This method classifies segments based on their proximity to neighboring training regions. See
    <a href="BackgroundKNN.htm">
     Background on K Nearest Neighbor
    </a>
    for more information. The KNN method is slower compared to PCA, particularly when your segmentation image has thousands of segments. However, it is a more rigorous method that more accurately distinguishes between similar classes. You only need to define one class in order to proceed with KNN&#160;classification.
   </li>
   <li value="2">
    <b>
     PCA:
    </b>
    This method assigns segments to classes using a principal components analysis. You must define at least two classes with a minimum of two training regions each. See
    <a href="BackgroundPCA.htm">
     Background on Principal Components Analysis
    </a>
    for more information.
   </li>
   <li value="3">
    <b>
     SVM:
    </b>
    This is the most rigorous of the three classification methods, so processing time will be slower. See
    <a href="BackgroundSVM.htm">
     Background on Support Vector Machine
    </a>
    for more information. Each class must have at least two training samples; otherwise, the class will be excluded from classification.
   </li>
  </ul>
  <p>
   Enable the
   <b>
    Allow Unclassified
   </b>
   option to allow segments to be unclassified when the classifier cannot determine suitable classes for them. This option is enabled by default.
  </p>
  <p>
   After the KNN, PCA, or SVM method runs, each segment is assigned the class with the highest class confidence value. Segments with class confidence values less than the percentage you set with the
   <b>
    Threshold
   </b>
   slider are assigned to "unclassified." The default
   <b>
    Threshold
   </b>
   value is 5 percent, which means segments that have less than 5 percent confidence in each class are set to "unclassified."
  </p>
  <p>
   As you increase the
   <b>
    Threshold
   </b>
   slider, the classifier will allow more unclassified segments. As you decrease the value of the
   <b>
    Threshold
   </b>
   slider, the classifier forces more segments into classes. A value of 0 means that all segments will be classified, except with the PCA method where some unclassified regions may remain.
  </p>
  <p>
   Enable the
   <b>
    Preview
   </b>
   option to view classification results within a Preview Portal. You can preview the effects of changing classification options before classifying the entire image.
  </p>
  <h2>
   <a name="Export">
   </a>
   Export Classification Results
  </h2>
  <p>
   In this step, you will select the types of images, vectors, and statistics to export to various formats. By default, files are saved to the directory that you specify in the
   <a style="font-weight: bold;" href="../../Preferences.htm#OutputDirectory">
    Output Directory
   </a>
   preference. When the export is complete, the workflow view closes. The original data and the export data display in the Image window view. The available output options vary, depending on your workflow.
  </p>
  <ul>
   <li value="1">
    <a href="#Rule-Bas">
     Rule-Based and Example-Based Classification
    </a>
   </li>
   <li value="2">
    <a href="#Segment-">
     Segment-Only
    </a>
   </li>
  </ul>
  <h3>
   <a name="Rule-Bas">
   </a>
   Rule-Based and Example-Based Classification
  </h3>
  <p>
   Choose the classification file types you want to save.
  </p>
  <h4>
   Export Vector Tab
  </h4>
  <ul>
   <li value="1">
    <b>
     Export Classification Vectors:
    </b>
    Save all classes to a single shapefile with a filename of
    <code>
     <i>
      &lt;prefix&gt;
     </i>
     _vectors.shp
    </code>
    , or to a geodatabase. Shapefiles have a maximum file size of 2 GB, so if the image has a large number of classes and the resulting shapefile exceeds this file size, it will be broken into smaller shapefiles. Shapefiles larger than 1.5 GB cannot be displayed. To avoid these issues when working with large datasets, you can save the vectors to a geodatabase.
   </li>
   <li value="2">
    <b>
     Merge Adjacent Features:
    </b>
    Select this option if you are confident that adjacent polygons belong to the same class and you want to consolidate them into a single polygon. This results in a smaller file size. This option merges all adjacent segments at once across the entire image; you cannot select specific polygons to merge.
   </li>
   <p class="Tip" madcap:autonum="&lt;b&gt;Tip: &lt;/b&gt;">
    <span class="autonumber">
     <span>
      <b>
       Tip:
      </b>
     </span>
    </span>
    A good example is an angled rooftop that reveals different brightness levels from an aerial sensor, depending on the sun's angle. The segmentation step would typically create multiple regions within the rooftop, each with different spectral values. But if you build a good rule set that identifies rooftops, the classification image (and/or shapefile) will assign these regions to the same class. Since you know that they all belong to one rooftop, you can choose to merge the adjacent segments so that the entire rooftop is one polygon.
   </p>
   <li value="3">
    <b>
     Export Attributes:
    </b>
    Select this option if you want to include the spatial, spectral, and texture attributes that were computed for each region in the output shapefile.
   </li>
  </ul>
  <h4>
   Export Raster Tab
  </h4>
  <ul>
   <li value="1">
    <b>
     Export Classification Image:
    </b>
    Create an image in ENVI raster format whose pixel values represent different classes. The filename will be
    <code>
     <i>
      &lt;prefix&gt;
     </i>
     _class.dat
    </code>
    .
   </li>
   <li value="2">
    <b>
     Export Segmentation Image:
    </b>
    Create a multispectral image in ENVI raster format that shows the regions defined by segmentation; each region is assigned the mean spectral values of all the pixels that belong to that region. The filename will be
    <code>
     <i>
      &lt;prefix&gt;
     </i>
     _segmentation.dat
    </code>
    .
   </li>
  </ul>
  <h4>
   Advanced Export Tab
  </h4>
  <ul>
   <li value="1">
    <b>
     Export Attributes Image:
    </b>
    Create a multi-layer image in ENVI raster format where each layer represents the values of a specific attribute. The filename will be
    <code>
     <i>
      &lt;prefix&gt;
     </i>
     _attributes.dat
    </code>
    . When you select this option, a new dialog appears that lets you select which attributes to export to an attribute image. The
    <b>
     Selected Attributes
    </b>
    column is initially populated with the attributes you used in your rule set. If an attribute does not contain any valid values, then that attribute band will be assigned pixel values of 0. See
    <a href="#Selectin">
     Selecting Attributes for Classification
    </a>
    for further details on using this dialog.
   </li>
   <li value="2">
    <b>
     Export Confidence Image:
    </b>
    Create an image in ENVI raster format that shows the relative confidence of each object belonging to a class. The higher the brightness of an object, the higher the confidence that the object belongs to the class. If an object is very dark, it likely does not belong to the class. This is a multi-layer file, with each layer representing one class. The filename will be
    <code>
     <i>
      &lt;prefix&gt;
     </i>
     _confidence.dat
    </code>
    .
   </li>
  </ul>
  <h4>
   Auxiliary Export Tab
  </h4>
  <ul>
   <li value="1">
    <b>
     Export Feature Examples:
    </b>
    Example-based classification only. Save the training samples that you selected for all classes to an XML file named
    <code>
     &lt;
     <i>
      prefix
     </i>
     &gt;_trainingset.ftr
    </code>
    .
   </li>
   <li value="2">
    <b>
     Export Feature Ruleset:
    </b>
    Rule-based classification only. Save the rules that you defined to a file named
    <code>
     <i>
      &lt;prefix&gt;
     </i>
     _ruleset.rul
    </code>
    .
   </li>
   <li value="3">
    <b>
     Export Processing Report:
    </b>
    Create a text report that summarizes the segmentation options, rules, and attributes that you used to classify the image. The filename will be
    <code>
     <i>
      &lt;prefix&gt;
     </i>
     _report.txt
    </code>
    .
   </li>
  </ul>
  <h3>
   <a name="Segment-">
   </a>
   Segment-Only
  </h3>
  <h4>
   Export Vector Tab
  </h4>
  <ul>
   <li value="1">
    <b>
     Export Segmentation Vectors:
    </b>
    Save the regions in the segmentation image to a shapefile. Shapefiles have a maximum file size of 2 GB, so if your image has a large number of segments and the resulting shapefile exceeds this file size, it will be broken into smaller shapefiles. Shapefiles larger than 1.5 GB cannot be displayed. To avoid these issues when working with large datasets, you can save the vectors to a geodatabase.
   </li>
  </ul>
  <ul>
   <li value="1">
    <b>
     Export Attributes:
    </b>
    Select this option if you want to include the spatial, spectral, and texture attributes that were computed for each region in the output shapefile.
   </li>
  </ul>
  <h4>
   Export Raster Tab
  </h4>
  <ul>
   <li value="1">
    <b>
     Export Segmentation Image:
    </b>
    Create a multispectral image in ENVI&#160;raster format that shows the regions defined by segmentation; each region is assigned the mean spectral values of all the pixels that belong to that region.
   </li>
  </ul>
  <h4>
   Advanced Export Tab
  </h4>
  <ul>
   <li value="1">
    <b>
     Export Attributes Image:
    </b>
    Create a multi-layer image in ENVI raster format where each layer represents the values of a specific attribute. When you select this option, a new dialog appears that lets you select which attributes to export to an attribute image. The
    <b>
     Selected Attributes
    </b>
    column is initially empty. Select the attribute name(s) that you want to export in the
    <b>
     Available Attributes
    </b>
    column, and click the
    <b>
     Add Selected Attribute
    </b>
    button. If an attribute does not contain any valid values, then that attribute band will be assigned pixel values of 0. See
    <a href="#Selectin">
     Selecting Attributes for Classification
    </a>
    for further details on using this dialog.
   </li>
  </ul>
  <h4>
   Auxiliary Export Tab
  </h4>
  <ul>
   <li value="1">
    <b>
     Export Processing Report:
    </b>
    Create a report that summarizes the segmentation options, rules, and attributes that you used to classify the image.
   </li>
  </ul>
  <div class="mp_footer">
   Copyright ©
   <span class="DocumentTitleCopyrightYear">
    2012
   </span>
   <![CDATA[ ]]>
   <span class="DocumentTitleCopyrightCompanyName">
    Exelis Visual Information Solutions, Inc.
   </span>
   All Rights Reserved.
  </div>
  <script type="text/javascript" src="../../SkinSupport/MadCapBodyEnd.js">
  </script>
 </body>
</html>