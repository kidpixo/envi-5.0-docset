<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns:madcap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" madcap:lastblockdepth="2" madcap:lastheight="135.6667" madcap:lastwidth="592" madcap:disablemasterstylesheet="true" madcap:tocpath="Feature Extraction|Reference" madcap:medium="non-print" madcap:inpreviewmode="false" madcap:preloadimages="false" madcap:runtimefiletype="Topic" madcap:targettype="WebHelp" lang="en-us" xml:lang="en-us" madcap:pathtohelpsystem="../../../" madcap:helpsystemfilename="ENVIHelp.xml" madcap:searchtype="Stem">
 <!-- saved from url=(0014)about:internet -->
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>
   Segmentation Algorithms Background
  </title>
  <link href="../../SkinSupport/MadCap.css" rel="stylesheet" />
  <link href="../../Resources/Stylesheets/Doc_Style.css" rel="stylesheet" />
  <script src="../../SkinSupport/MadCapAll.js" type="text/javascript">
  </script>
 </head>
 <body>
  <p class="MCWebHelpFramesetLink" style="display: none;">
   <a href="../../../ENVIHelp_CSH.htm#FindFeatures/FeatureExtraction/BackgroundSegmentationAlgorithm.htm" style="">
    Open topic with navigation
   </a>
  </p>
  <div class="MCBreadcrumbsBox_0">
   <span class="MCBreadcrumbsPrefix">
    <![CDATA[ ]]>
   </span>
   <a class="MCBreadcrumbsLink" href="ExtractFeatures.htm">
    Feature Extraction
   </a>
   <span class="MCBreadcrumbsDivider">
    &gt;
   </span>
   <a class="MCBreadcrumbsLink" href="#">
    Reference
   </a>
   <span class="MCBreadcrumbsDivider">
    &gt;
   </span>
   <span class="MCBreadcrumbs">
    Segmentation Algorithms Background
   </span>
  </div>
  <h2>
   Segmentation Algorithms Background
   <a name="kanchor323">
   </a>
  </h2>
  <p>
   The segmentation process in Feature Extraction is based on a
   <i>
    watershed by immersion
   </i>
   algorithm developed by
   <a href="#Referenc">
    Vincent and Soille (1991)
   </a>
   that equates pixel DN values in an image with elevation points on a topographic surface.
  </p>
  <p>
   Basins fill up with water starting at the lowest points, and dams are built where water coming from different basins would meet. When the water level has reached the highest peak in the landscape, the process stops. The landscape is thus divided into regions separated by dams, called
   <i>
    watersheds
   </i>
   (
   <a href="#Referenc">
    Roerdink and Meijster 2001
   </a>
   ).
  </p>
  <p>
   A similar process occurs in digital imagery. The darker a pixel, the lower its "elevation"; this type of pixel is called a
   <i>
    minimum
   </i>
   . The Vincent and Soille watershed algorithm sorts pixels by increasing greyscale value, then begins with the minimum pixels and "floods" the image, partitioning the image into basins (regions with similar pixel intensities) based on the computed watersheds. The result is a
   <i>
    segmentation image
   </i>
   , where each region is assigned the mean spectral values of all the pixels that belong to that region.
  </p>
  <p class="Tip" madcap:autonum="&lt;b&gt;Tip: &lt;/b&gt;">
   <span class="autonumber">
    <span>
     <b>
      Tip:
     </b>
    </span>
   </span>
   The segmentation image appears in the display after you click
   <b>
    Next
   </b>
   in the
   <a href="Example_Based_Classification.htm#SegmentImages">
    Object Creation panel
   </a>
   of the Feature Extraction workflow.
  </p>
  <p>
   Since the watershed algorithm groups pixels based on a single value, multispectral images need to be converted to a single-band image for processing.  Each pixel is converted to an intensity value by averaging it across the bands that you select in the Object Creation panel.
  </p>
  <p>
   Two different methods are provided for applying a watershed algorithm to imagery.
  </p>
  <h3>
   Edge Method
  </h3>
  <p>
   Objects of interest often have clear boundaries represented by relatively large gradient magnitudes, while the internal part of the objects may have a more uniform intensity (with little or no gradient magnitude). Use the
   <b>
    Edge
   </b>
   method for identifying features with distinct boundaries such as buildings or vehicles.
  </p>
  <p>
   With the
   <b>
    Edge
   </b>
   method,
   <span class="DocumentTitleProductName">
    ENVI
   </span>
   computes a gradient image using a Sobel edge detection method, where the highest pixel values represent areas with the highest pixel contrast. The watershed algorithm is applied to the gradient image rather than the original image. The watershed algorithm floods the image starting with the lowest gradient values (the uniform part of the objects) to the highest gradient values (the edges).
  </p>
  <h3>
   Intensity Method
  </h3>
  <p>
   The most common case for using the
   <b>
    Intensity
   </b>
   method is with images that represent a
   <i>
    potential
   </i>
   surface where particles are drawn to minimum points. Examples include digital elevation models (DEMs), images of electromagnetic fields, or images of gravitational potential.
  </p>
  <p>
   With the
   <b>
    Intensity
   </b>
   method, the watershed algorithm floods the image starting with the lowest intensity values and continuing to the highest intensity values.
  </p>
  <p>
   Here are two examples that illustrate when you might want to use the
   <b>
    Intensity
   </b>
   method:
  </p>
  <h4>
   Topography
  </h4>
  <p>
   The most common use of the
   <b>
    Intensity
   </b>
   method is to extract watershed boundaries from DEMs. The watershed algorithm begins with the pixels with the lowest elevation values and "floods" the image, computing watershed boundaries and creating regions based on separate catchment basins. Hydrologists may want to use the
   <b>
    Intensity
   </b>
   method with DEMs to evaluate different flooding scenarios and to create shapefiles of segments that represent specific watersheds.
  </p>
  <h4>
   Performing Segmentation on a Gradient Image
  </h4>
  <p>
   Suppose you already created an effective gradient image outside of Feature Extraction that shows strong boundaries between features of interest. For example, you used a Sobel filter to enhance layers of tissue in medical imagery. You can use the resulting image as input into segmentation by following these general steps:
  </p>
  <ol>
   <li value="1">
    Create a layer stack that consists of the original image's spectral bands plus the gradient image.
   </li>
   <li value="2">
    Click
    <b>
     Select Segment Bands
    </b>
    . From the layer stack, choose only the band representing the gradient image, then click
    <b>
     OK
    </b>
    . You will perform segmentation on just the gradient image.
   </li>
   <li value="3">
    Click
    <b>
     Select Merge Bands
    </b>
    . From the layer stack, choose only the spectral bands from the original image. You will perform merging only on the spectral attributes.
   </li>
   <li value="4">
    Select the
    <b>
     Intensity
    </b>
    method under Segment Settings. (You do not want to use the
    <b>
     Gradient
    </b>
    method on a gradient image.)
   </li>
  </ol>
  <h3>
   Scale Level
  </h3>
  <p>
   The
   <b>
    Scale Level
   </b>
   is computed from a normalized cumulative distribution function (CDF) of the pixel values in the image. For example, if you select
   <b>
    Edge
   </b>
   and choose a
   <b>
    Scale Level
   </b>
   of
   <b>
    20
   </b>
   , the lowest 20 percent of gradient magnitude values are discarded from the gradient image. Increasing the
   <b>
    Scale Level
   </b>
   keeps objects with the most distinct edges.
  </p>
  <p>
   With the
   <b>
    Intensity
   </b>
   method, choosing a
   <b>
    Scale Level
   </b>
   of
   <b>
    20
   </b>
   with a DEM begins watershed flooding from the lowest 20% elevation, continuing upward. Flooding the lowest elevations first provides a more accurate analysis of the watersheds at higher elevations.
  </p>
  <p>
   <a name="Referenc">
   </a>
   <b>
    References
   </b>
  </p>
  <p>
   Roerdink, Jos B.T.M., and A. Meijster. "The watershed transform: definitions, algorithms, and parallelization strategies,"
   <i>
    Fundamenta Informaticae
   </i>
   41 (2001): 187-228.
  </p>
  <p>
   Vincent, L., and P. Soille. "Watersheds in digital spaces: an efficient algorithm based on immersion simulations,"
   <i>
    IEEE Transactions on Pattern Analysis and Machine Intelligence
   </i>
   13, no. 6 (1991): 583-598.
  </p>
  <div class="mp_footer">
   Copyright Â©
   <span class="DocumentTitleCopyrightYear">
    2012
   </span>
   <![CDATA[ ]]>
   <span class="DocumentTitleCopyrightCompanyName">
    Exelis Visual Information Solutions, Inc.
   </span>
   All Rights Reserved.
  </div>
  <script type="text/javascript" src="../../SkinSupport/MadCapBodyEnd.js">
  </script>
 </body>
</html>